{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjhIMIQWtKT56xx0m2omnP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ilirsheraj/DUDL/blob/main/Chapter_12_Weights_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Xavier & Kaiming Initializations"
      ],
      "metadata": {
        "id": "I4lNuqZX72I_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdOup97g7p0D"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "\n",
        "import sklearn.metrics as skm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "display.set_matplotlib_formats(\"svg\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the small MNIST dataset that comes with colab\n",
        "data = np.loadtxt(open(\"sample_data/mnist_train_small.csv\", \"rb\"),delimiter=\",\")\n",
        "\n",
        "# Extract the labels and remove them from data\n",
        "labels = data[:,0]\n",
        "data = data[:,1:]\n",
        "\n",
        "# Normalize data on range 0-1\n",
        "dataNorm = data/np.max(data)"
      ],
      "metadata": {
        "id": "PlAm5m4378Fm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}